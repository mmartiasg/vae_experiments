{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'enum_type_wrapper' from 'google.protobuf.internal' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/__init__.py:37\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_typing\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m module_util \u001B[38;5;28;01mas\u001B[39;00m _module_util\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlazy_loader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LazyLoader \u001B[38;5;28;01mas\u001B[39;00m _LazyLoader\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/__init__.py:37\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# import it in modules_with_exports.py instead.\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# go/tf-wildcard-import\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tensorflow \u001B[38;5;28;01mas\u001B[39;00m _pywrap_tensorflow\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m context\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# pylint: enable=wildcard-import\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Bring in subpackages.\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m data\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/context.py:28\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mabsl\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logging\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m function_pb2\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config_pb2\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m rewriter_config_pb2\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/core/framework/function_pb2.py:5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# -*- coding: utf-8 -*-\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Generated by the protocol buffer compiler.  DO NOT EDIT!\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# source: tensorflow/core/framework/function.proto\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"Generated protocol buffer code.\"\"\"\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minternal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m builder \u001B[38;5;28;01mas\u001B[39;00m _builder\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m descriptor \u001B[38;5;28;01mas\u001B[39;00m _descriptor\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m descriptor_pool \u001B[38;5;28;01mas\u001B[39;00m _descriptor_pool\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.9/site-packages/google/protobuf/internal/builder.py:40\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;124;03m\"\"\"Builds descriptors, message classes and services for generated _pb2.py.\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \n\u001B[1;32m     33\u001B[0m \u001B[38;5;124;03mThis file is only called in python generated _pb2.py files. It builds\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;124;03mdescriptors, message classes and services that users can directly use\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;124;03min generated code.\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     38\u001B[0m __author__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjieluo@google.com (Jie Luo)\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minternal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m enum_type_wrapper\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m message \u001B[38;5;28;01mas\u001B[39;00m _message\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m reflection \u001B[38;5;28;01mas\u001B[39;00m _reflection\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'enum_type_wrapper' from 'google.protobuf.internal' (unknown location)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T23:04:07.877013Z",
     "start_time": "2024-03-23T23:04:07.706094Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T23:03:58.564705Z",
     "start_time": "2024-03-23T23:03:57.330245Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'enum_type_wrapper' from 'google.protobuf.internal' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/__init__.py:37\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_typing\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m module_util \u001B[38;5;28;01mas\u001B[39;00m _module_util\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlazy_loader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LazyLoader \u001B[38;5;28;01mas\u001B[39;00m _LazyLoader\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/__init__.py:37\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# import it in modules_with_exports.py instead.\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# go/tf-wildcard-import\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tensorflow \u001B[38;5;28;01mas\u001B[39;00m _pywrap_tensorflow\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m context\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# pylint: enable=wildcard-import\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Bring in subpackages.\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m data\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/context.py:28\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mabsl\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logging\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m function_pb2\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config_pb2\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m rewriter_config_pb2\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/core/framework/function_pb2.py:5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# -*- coding: utf-8 -*-\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Generated by the protocol buffer compiler.  DO NOT EDIT!\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# source: tensorflow/core/framework/function.proto\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"Generated protocol buffer code.\"\"\"\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minternal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m builder \u001B[38;5;28;01mas\u001B[39;00m _builder\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m descriptor \u001B[38;5;28;01mas\u001B[39;00m _descriptor\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m descriptor_pool \u001B[38;5;28;01mas\u001B[39;00m _descriptor_pool\n",
      "File \u001B[0;32m~/miniforge3/lib/python3.9/site-packages/google/protobuf/internal/builder.py:40\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;124;03m\"\"\"Builds descriptors, message classes and services for generated _pb2.py.\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \n\u001B[1;32m     33\u001B[0m \u001B[38;5;124;03mThis file is only called in python generated _pb2.py files. It builds\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;124;03mdescriptors, message classes and services that users can directly use\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;124;03min generated code.\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     38\u001B[0m __author__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjieluo@google.com (Jie Luo)\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minternal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m enum_type_wrapper\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m message \u001B[38;5;28;01mas\u001B[39;00m _message\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m reflection \u001B[38;5;28;01mas\u001B[39;00m _reflection\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'enum_type_wrapper' from 'google.protobuf.internal' (unknown location)"
     ]
    }
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use to generate new data by manipulation\n",
    "\n",
    "## What is this?\n",
    "VAE stands for Variational Auto Encoder. Which means that is trained to reproduce or reconstruct from a latent space the input. Is an strategy to learn that latent space\n",
    "\n",
    "It has 2 important blocks the Encoder wich will be responsable for condensing the data into a low dimensional latent space or just a vector.\n",
    "And the Decoder by taking one point(how do you choose a point? By sampling) from the latent space is able to reconstruct a new image.\n",
    "\n",
    "## How do VAEs build a latent space?\n",
    "That is what difference a VAE from a AE that the V which means variational and allows the VAE to create continuous and structured latent spaces.\n",
    "\n",
    "## How do you sample the latent space?\n",
    "\n",
    "\n",
    "The latent space is structured, non sparse continuous and low dimentional where each direction encode a meanful axis of variation(V) of the data. And that means it can be manipulated with content vectors. Vectors that are isolated and represent a concept.\n",
    "Like the concept of smile another image representation can be added to the smile concept vector then passed to the decoder to create a new image with the person smiling.\n",
    "\n",
    "```There are concept vectors for any independent direction of the latent space```\n",
    "```deeplearning with bayesian inference```\n",
    "\n",
    "## Steps\n",
    "- Build the encoder\n",
    "    - The output will be 2 vectors mean and variance\n",
    "- Build the sampler using a random small vector along with the 2 vectors the encoder will give us\n",
    "    - normal dist value = mean * exp(std) * epsilon / epsilon is a random small vector from the latent space\n",
    "- Build the loss\n",
    "    - kubell-divergence\n",
    "    - reconstruction loss mean already coded in keras\n",
    "- Build the decoder\n",
    "    - the decoder will take the sampled input and reconstruct it to a valid image!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "\n",
    "The encoder will transform the image into 2 parameters vectors that will be used to form a normal distribution, mean_vector and standard_deviation_vector"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATASET_BASE_PATH = \"../../datasets\"\n",
    "\n",
    "DATASET_NAME = \"art_images\"\n",
    "\n",
    "FULL_PATH = \"\".join([DATASET_BASE_PATH, os.sep, DATASET_NAME])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T22:17:45.487132Z",
     "start_time": "2024-03-23T22:17:45.484923Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T22:17:48.003737Z",
     "start_time": "2024-03-23T22:17:47.986814Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m IMAGE_OUTPUT_SHAPE \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m128\u001B[39m, \u001B[38;5;241m128\u001B[39m)\n\u001B[1;32m      3\u001B[0m CHANNELS \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m----> 5\u001B[0m input_image \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mimage_dataset_from_directory(FULL_PATH,\n\u001B[1;32m      6\u001B[0m                                                              label_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m      7\u001B[0m                                                                image_size\u001B[38;5;241m=\u001B[39mIMAGE_INPUT_SHAPE,\n\u001B[1;32m      8\u001B[0m                                                                  batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m,\n\u001B[1;32m      9\u001B[0m                                                                  shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     10\u001B[0m                                                                  color_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrayscale\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     11\u001B[0m                                                                  smart_resize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     13\u001B[0m output_image \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mimage_dataset_from_directory(FULL_PATH,\n\u001B[1;32m     14\u001B[0m                                                              label_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     15\u001B[0m                                                                image_size\u001B[38;5;241m=\u001B[39mIMAGE_OUTPUT_SHAPE,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m                                                                  color_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrayscale\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     19\u001B[0m                                                                  smart_resize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "IMAGE_INPUT_SHAPE = (64, 64)\n",
    "IMAGE_OUTPUT_SHAPE = (128, 128)\n",
    "CHANNELS = 1\n",
    "\n",
    "input_image = tf.keras.utils.image_dataset_from_directory(FULL_PATH,\n",
    "                                                             label_mode=None,\n",
    "                                                               image_size=IMAGE_INPUT_SHAPE,\n",
    "                                                                 batch_size=256,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 color_mode=\"grayscale\",\n",
    "                                                                 smart_resize=True)\n",
    "\n",
    "output_image = tf.keras.utils.image_dataset_from_directory(FULL_PATH,\n",
    "                                                             label_mode=None,\n",
    "                                                               image_size=IMAGE_OUTPUT_SHAPE,\n",
    "                                                                 batch_size=256,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 color_mode=\"grayscale\",\n",
    "                                                                 smart_resize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in whole_dataset:\n",
    "    for image in batch:\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset = whole_dataset.map(lambda x: x/255., num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIMS = 2\n",
    "IMAGE_CHANNELS = 1\n",
    "PROY_DIM = 16 #16\n",
    "# the input is the output of the sample(encoder(image))\n",
    "# CHANNELS_ENCODER_OUTPUT = 256\n",
    "CONVS_NUMBER_ENCODER = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to use a fix size.. This should not be a limitation in the future.\n",
    "# If I create a class I can surpass that limitation\n",
    "X_input_encoder = tf.keras.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))\n",
    "filters_decoder = 16\n",
    "\n",
    "# add more convs\n",
    "#Last conv\n",
    "X = tf.keras.layers.Conv2D(filters=filters_decoder, kernel_size=3, activation=\"relu\", strides=2, padding=\"same\")(X_input_encoder)\n",
    "\n",
    "for channel_index in range(CONVS_NUMBER_ENCODER-1):\n",
    "    filters_decoder *= 2\n",
    "    X = tf.keras.layers.Conv2D(filters=filters_decoder, kernel_size=3, activation=\"relu\", strides=2, padding=\"same\")(X)\n",
    "    CHANNELS_ENCODER_OUTPUT = filters_decoder\n",
    "    #Adding more convs diminish kl divergence at first then increases it??\n",
    "\n",
    "X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "# Try a proyection model sequence latter\n",
    "X = tf.keras.layers.Dense(units=PROY_DIM, activation=\"relu\")(X)\n",
    "# X = tf.keras.Sequential([tf.keras.layers.Dense(units=PROY_DIM, activation=\"relu\"), tf.keras.layers.Dense(units=PROY_DIM)])(X)\n",
    "\n",
    "z_mean = tf.keras.layers.Dense(units=LATENT_DIMS, name=\"z_mean\")(X)\n",
    "z_log_var = tf.keras.layers.Dense(units=LATENT_DIMS, name=\"z_log_var\")(X)\n",
    "\n",
    "encoder = tf.keras.Model(inputs=X_input_encoder, outputs=[z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 16)   160         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 16, 16, 32)   4640        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 8, 64)     18496       ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 4, 4, 128)    73856       ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 2, 2, 256)    295168      ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1024)         0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           16400       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            34          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            34          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 408,788\n",
      "Trainable params: 408,788\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampler!\n",
    "\n",
    "We are sampling from a normal distribution\n",
    "\n",
    "normal = mu + exp(sigma) * epsilon\n",
    "\n",
    "epsilon is a random number from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler(tf.keras.layers.Layer):\n",
    "    def call(self, z_mean, z_sigma):\n",
    "        # get the batch size\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        latent_dim = tf.shape(z_mean)[1]\n",
    "\n",
    "        #Epsilon should be the same size as our vectors\n",
    "        # here we are in the training and everything gets processed in batch\n",
    "        epsilon = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "\n",
    "        #This returns a sample point from the distribution we are trying to find.\n",
    "        # A normal distribution\n",
    "        # Why over 2? is that 2 the N elements?\n",
    "        return z_mean + tf.math.exp(z_sigma/2) * epsilon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image is 256 but we have 2 transpose layers the image will get upscaled 2 times and we only applied 1 layer of convs with strides 2 \n",
    "# At this point the image is 128 but if we are going to upscale 2 times for the image to be again 256 it should be 64\n",
    "CONVS_NUMBER = 3\n",
    "IMAGE_HEIGHT_DECODE = IMAGE_WIDTH_DECODE = math.ceil(IMAGE_HEIGHT/(2**CONVS_NUMBER))\n",
    "\n",
    "X_input_decoder = tf.keras.Input(shape=(LATENT_DIMS,))\n",
    "\n",
    "X = tf.keras.layers.Dense(units=IMAGE_HEIGHT_DECODE * IMAGE_WIDTH_DECODE * CHANNELS_ENCODER_OUTPUT)(X_input_decoder)\n",
    "X = tf.keras.layers.Reshape((IMAGE_HEIGHT_DECODE, IMAGE_WIDTH_DECODE, CHANNELS_ENCODER_OUTPUT))(X)\n",
    "\n",
    "filters = CHANNELS_ENCODER_OUTPUT\n",
    "for channel_index in range(CONVS_NUMBER):\n",
    "    X = tf.keras.layers.Conv2DTranspose(filters, 3, activation=\"relu\", strides=2, padding=\"same\")(X)\n",
    "    filters = math.ceil(filters/2)\n",
    "\n",
    "X_decoder_output = tf.keras.layers.Conv2D(IMAGE_CHANNELS, 3, activation=\"sigmoid\", padding=\"same\")(X)\n",
    "\n",
    "#X_input_decoder latent input\n",
    "decoder = tf.keras.Model(X_input_decoder, X_decoder_output, name=\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16384)             49152     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 16, 16, 256)      590080    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 128)      295040    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 64)       73792     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,008,641\n",
      "Trainable params: 1,008,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tf.constant(np.random.normal(size=(8, 5, 4, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 5, 4, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
       "array([[-9.24349543],\n",
       "       [-6.53157088],\n",
       "       [-2.33653475],\n",
       "       [ 2.01187244],\n",
       "       [ 3.40247619],\n",
       "       [ 0.09401621],\n",
       "       [-4.24325604],\n",
       "       [-1.22383544]])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(sample, axis=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-2.2587909613984563>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.reduce_sum(sample, axis=(1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, sampler, **kwars):\n",
    "        \"\"\" \n",
    "         It has 3 main blocks \n",
    "            - encoder\n",
    "            - decoder\n",
    "            - sampler\n",
    "        \"\"\"\n",
    "        super().__init__(**kwars)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sampler = sampler\n",
    "\n",
    "        # sum all losses\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_flat_loss\")\n",
    "\n",
    "        # how close the reconstructed sample by the decoder is to the original source\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "\n",
    "        # divergence from the distribution created to model the latent space and the real one which is a normal distribution\n",
    "        # From where the epsilon point comes from?\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_sigma = self.encoder(inputs)\n",
    "        return self.decoder(self.sampler(z_mean, z_sigma))\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss_tracker,\n",
    "                self.reconstruction_loss_tracker,\n",
    "                self.kl_loss_tracker]\n",
    "    \n",
    "    def train_step(self, batch_data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_sigma = self.encoder(batch_data)\n",
    "            sampled_point_z = self.sampler(z_mean, z_sigma)\n",
    "            reconstructed_data = self.decoder(sampled_point_z)\n",
    "\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                # The image needs to be normalized between 0 and 1 for this to make sense\n",
    "                # binary difference between input data and reconstructed\n",
    "                tf.reduce_sum(tf.keras.losses.binary_crossentropy(batch_data, reconstructed_data),\n",
    "                              # sum by sample, reduce the whole row to 1 value\n",
    "                              axis=(1, 2))\n",
    "            )\n",
    "\n",
    "            kl_loss = -0.5 * (1 + z_sigma - tf.math.square(z_mean) - tf.math.exp(z_sigma))\n",
    "\n",
    "            # this adds all 2 losses into one\n",
    "            # how well the input was reconstructed and the distribution difference to create the latent space\n",
    "            total_loss = reconstruction_loss + tf.reduce_mean(kl_loss)\n",
    "\n",
    "        # Standard way to propagate the error signal?\n",
    "        gradients = tape.gradient(total_loss, self.trainable_weights)\n",
    "        # gradients = tape.gradient(total_loss, [z_mean, z_sigma])\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        # self.optimizer.apply_gradients(zip(gradients, [z_mean, z_sigma]))\n",
    "\n",
    "        # add and average the loss so far up to this batch\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"total_loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder=encoder, decoder=decoder, sampler=Sampler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer=tf.keras.optimizers.legacy.Adam(), run_eagerly=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: add a callback to preview the output of the generator vs the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2820.9522 - reconstruction_loss: 2804.4683 - kl_loss: 0.7071\n",
      "Epoch 2/300\n",
      "69/69 [==============================] - 13s 187ms/step - total_loss: 2705.9117 - reconstruction_loss: 2685.4678 - kl_loss: 3.3997\n",
      "Epoch 3/300\n",
      "69/69 [==============================] - 13s 191ms/step - total_loss: 2675.6457 - reconstruction_loss: 2670.2405 - kl_loss: 2.9907\n",
      "Epoch 4/300\n",
      "69/69 [==============================] - 13s 190ms/step - total_loss: 2673.0759 - reconstruction_loss: 2669.2046 - kl_loss: 2.9376\n",
      "Epoch 5/300\n",
      "69/69 [==============================] - 14s 193ms/step - total_loss: 2672.3383 - reconstruction_loss: 2668.8513 - kl_loss: 2.9250\n",
      "Epoch 6/300\n",
      "69/69 [==============================] - 14s 192ms/step - total_loss: 2673.1755 - reconstruction_loss: 2668.1179 - kl_loss: 2.8909\n",
      "Epoch 7/300\n",
      "69/69 [==============================] - 13s 189ms/step - total_loss: 2671.4102 - reconstruction_loss: 2668.2061 - kl_loss: 2.8986\n",
      "Epoch 8/300\n",
      "69/69 [==============================] - 13s 189ms/step - total_loss: 2672.1970 - reconstruction_loss: 2667.5098 - kl_loss: 2.8902\n",
      "Epoch 9/300\n",
      "69/69 [==============================] - 14s 195ms/step - total_loss: 2669.7320 - reconstruction_loss: 2667.5234 - kl_loss: 2.8912\n",
      "Epoch 10/300\n",
      "69/69 [==============================] - 14s 200ms/step - total_loss: 2672.4292 - reconstruction_loss: 2666.1606 - kl_loss: 2.9380\n",
      "Epoch 11/300\n",
      "69/69 [==============================] - 14s 201ms/step - total_loss: 2670.5180 - reconstruction_loss: 2664.9463 - kl_loss: 2.9800\n",
      "Epoch 12/300\n",
      "69/69 [==============================] - 14s 200ms/step - total_loss: 2671.3699 - reconstruction_loss: 2664.4619 - kl_loss: 3.0494\n",
      "Epoch 13/300\n",
      "69/69 [==============================] - 14s 201ms/step - total_loss: 2665.6954 - reconstruction_loss: 2662.2891 - kl_loss: 3.0920\n",
      "Epoch 14/300\n",
      "69/69 [==============================] - 14s 195ms/step - total_loss: 2665.6952 - reconstruction_loss: 2660.8235 - kl_loss: 3.1042\n",
      "Epoch 15/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2665.2531 - reconstruction_loss: 2659.8220 - kl_loss: 3.1579\n",
      "Epoch 16/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2663.2065 - reconstruction_loss: 2657.9688 - kl_loss: 3.1875\n",
      "Epoch 17/300\n",
      "69/69 [==============================] - 13s 188ms/step - total_loss: 2663.6014 - reconstruction_loss: 2658.6060 - kl_loss: 3.1777\n",
      "Epoch 18/300\n",
      "69/69 [==============================] - 14s 201ms/step - total_loss: 2661.3922 - reconstruction_loss: 2655.8577 - kl_loss: 3.2483\n",
      "Epoch 19/300\n",
      "69/69 [==============================] - 14s 197ms/step - total_loss: 2663.5827 - reconstruction_loss: 2660.4543 - kl_loss: 3.3823\n",
      "Epoch 20/300\n",
      "69/69 [==============================] - 14s 201ms/step - total_loss: 2663.3549 - reconstruction_loss: 2656.0076 - kl_loss: 3.2425\n",
      "Epoch 21/300\n",
      "69/69 [==============================] - 14s 195ms/step - total_loss: 2658.0840 - reconstruction_loss: 2653.7922 - kl_loss: 3.3474\n",
      "Epoch 22/300\n",
      "69/69 [==============================] - 13s 191ms/step - total_loss: 2658.9183 - reconstruction_loss: 2653.2688 - kl_loss: 3.3150\n",
      "Epoch 23/300\n",
      "69/69 [==============================] - 14s 196ms/step - total_loss: 2658.1547 - reconstruction_loss: 2655.3596 - kl_loss: 3.3826\n",
      "Epoch 24/300\n",
      "69/69 [==============================] - 14s 195ms/step - total_loss: 2658.7204 - reconstruction_loss: 2652.0542 - kl_loss: 3.3770\n",
      "Epoch 25/300\n",
      "69/69 [==============================] - 14s 198ms/step - total_loss: 2654.7556 - reconstruction_loss: 2651.1921 - kl_loss: 3.4220\n",
      "Epoch 26/300\n",
      "69/69 [==============================] - 14s 202ms/step - total_loss: 2656.2658 - reconstruction_loss: 2651.0371 - kl_loss: 3.4234\n",
      "Epoch 27/300\n",
      "69/69 [==============================] - 14s 196ms/step - total_loss: 2656.8335 - reconstruction_loss: 2651.2700 - kl_loss: 3.4247\n",
      "Epoch 28/300\n",
      "69/69 [==============================] - 14s 197ms/step - total_loss: 2657.2647 - reconstruction_loss: 2651.1514 - kl_loss: 3.4353\n",
      "Epoch 29/300\n",
      "69/69 [==============================] - 14s 197ms/step - total_loss: 2654.8136 - reconstruction_loss: 2650.9280 - kl_loss: 3.4418\n",
      "Epoch 30/300\n",
      "69/69 [==============================] - 14s 193ms/step - total_loss: 2657.4663 - reconstruction_loss: 2650.5859 - kl_loss: 3.5298\n",
      "Epoch 31/300\n",
      "69/69 [==============================] - 13s 190ms/step - total_loss: 2654.2559 - reconstruction_loss: 2649.6323 - kl_loss: 3.5158\n",
      "Epoch 32/300\n",
      "69/69 [==============================] - 13s 189ms/step - total_loss: 2655.0170 - reconstruction_loss: 2649.2188 - kl_loss: 3.4676\n",
      "Epoch 33/300\n",
      "69/69 [==============================] - 14s 193ms/step - total_loss: 2655.9112 - reconstruction_loss: 2652.1392 - kl_loss: 3.4460\n",
      "Epoch 34/300\n",
      "69/69 [==============================] - 14s 192ms/step - total_loss: 2655.3204 - reconstruction_loss: 2648.9976 - kl_loss: 3.5399\n",
      "Epoch 35/300\n",
      "69/69 [==============================] - 13s 189ms/step - total_loss: 2653.3615 - reconstruction_loss: 2647.9290 - kl_loss: 3.5297\n",
      "Epoch 36/300\n",
      "69/69 [==============================] - 13s 187ms/step - total_loss: 2653.7516 - reconstruction_loss: 2648.6096 - kl_loss: 3.5500\n",
      "Epoch 37/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2651.3802 - reconstruction_loss: 2646.6042 - kl_loss: 3.5584\n",
      "Epoch 38/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2656.7137 - reconstruction_loss: 2648.9746 - kl_loss: 3.5952\n",
      "Epoch 39/300\n",
      "69/69 [==============================] - 13s 188ms/step - total_loss: 2651.8356 - reconstruction_loss: 2647.2595 - kl_loss: 3.6279\n",
      "Epoch 40/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2652.0714 - reconstruction_loss: 2649.4766 - kl_loss: 3.7475\n",
      "Epoch 41/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2655.1163 - reconstruction_loss: 2648.1536 - kl_loss: 3.5337\n",
      "Epoch 42/300\n",
      "69/69 [==============================] - 14s 194ms/step - total_loss: 2653.3518 - reconstruction_loss: 2648.3103 - kl_loss: 3.6567\n",
      "Epoch 43/300\n",
      "69/69 [==============================] - 14s 198ms/step - total_loss: 2654.3183 - reconstruction_loss: 2649.6506 - kl_loss: 3.6752\n",
      "Epoch 44/300\n",
      "69/69 [==============================] - 13s 189ms/step - total_loss: 2652.6916 - reconstruction_loss: 2646.6204 - kl_loss: 3.5795\n",
      "Epoch 45/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2653.1664 - reconstruction_loss: 2647.3484 - kl_loss: 3.7057\n",
      "Epoch 46/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2652.0420 - reconstruction_loss: 2645.8481 - kl_loss: 3.6047\n",
      "Epoch 47/300\n",
      "69/69 [==============================] - 14s 195ms/step - total_loss: 2651.8187 - reconstruction_loss: 2648.4080 - kl_loss: 3.6856\n",
      "Epoch 48/300\n",
      "69/69 [==============================] - 14s 198ms/step - total_loss: 2649.0847 - reconstruction_loss: 2643.9380 - kl_loss: 3.5619\n",
      "Epoch 49/300\n",
      "69/69 [==============================] - 14s 195ms/step - total_loss: 2651.7051 - reconstruction_loss: 2646.7024 - kl_loss: 3.7280\n",
      "Epoch 50/300\n",
      "69/69 [==============================] - 14s 198ms/step - total_loss: 2650.4387 - reconstruction_loss: 2645.3750 - kl_loss: 3.6021\n",
      "Epoch 51/300\n",
      "69/69 [==============================] - 14s 197ms/step - total_loss: 2653.3222 - reconstruction_loss: 2646.0859 - kl_loss: 3.6509\n",
      "Epoch 52/300\n",
      "69/69 [==============================] - 14s 195ms/step - total_loss: 2647.5643 - reconstruction_loss: 2642.3887 - kl_loss: 3.6469\n",
      "Epoch 53/300\n",
      "69/69 [==============================] - 13s 184ms/step - total_loss: 2647.0131 - reconstruction_loss: 2641.9319 - kl_loss: 3.6603\n",
      "Epoch 54/300\n",
      "69/69 [==============================] - 13s 184ms/step - total_loss: 2647.5754 - reconstruction_loss: 2641.7451 - kl_loss: 3.6767\n",
      "Epoch 55/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2649.9364 - reconstruction_loss: 2643.1858 - kl_loss: 3.7489\n",
      "Epoch 56/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2648.7301 - reconstruction_loss: 2644.9619 - kl_loss: 3.7478\n",
      "Epoch 57/300\n",
      "69/69 [==============================] - 13s 184ms/step - total_loss: 2647.3219 - reconstruction_loss: 2641.2244 - kl_loss: 3.6816\n",
      "Epoch 58/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2644.6321 - reconstruction_loss: 2639.4011 - kl_loss: 3.7078\n",
      "Epoch 59/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2651.2964 - reconstruction_loss: 2645.6646 - kl_loss: 3.7030\n",
      "Epoch 60/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2646.2545 - reconstruction_loss: 2639.7532 - kl_loss: 3.6989\n",
      "Epoch 61/300\n",
      "69/69 [==============================] - 13s 179ms/step - total_loss: 2643.9115 - reconstruction_loss: 2637.1284 - kl_loss: 3.6914\n",
      "Epoch 62/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2645.7278 - reconstruction_loss: 2641.3005 - kl_loss: 3.8331\n",
      "Epoch 63/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2648.3881 - reconstruction_loss: 2640.5686 - kl_loss: 3.7662\n",
      "Epoch 64/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2644.2821 - reconstruction_loss: 2639.8750 - kl_loss: 3.7719\n",
      "Epoch 65/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2653.8825 - reconstruction_loss: 2644.9751 - kl_loss: 3.9488\n",
      "Epoch 66/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2645.7337 - reconstruction_loss: 2639.9858 - kl_loss: 3.8202\n",
      "Epoch 67/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2645.6033 - reconstruction_loss: 2638.8157 - kl_loss: 3.7593\n",
      "Epoch 68/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2647.7577 - reconstruction_loss: 2641.6362 - kl_loss: 3.9578\n",
      "Epoch 69/300\n",
      "69/69 [==============================] - 13s 192ms/step - total_loss: 2645.4286 - reconstruction_loss: 2640.8877 - kl_loss: 3.8050\n",
      "Epoch 70/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2646.6767 - reconstruction_loss: 2639.6331 - kl_loss: 3.7761\n",
      "Epoch 71/300\n",
      "69/69 [==============================] - 12s 177ms/step - total_loss: 2647.5473 - reconstruction_loss: 2641.6934 - kl_loss: 3.7565\n",
      "Epoch 72/300\n",
      "69/69 [==============================] - 12s 174ms/step - total_loss: 2642.9447 - reconstruction_loss: 2637.1475 - kl_loss: 3.7328\n",
      "Epoch 73/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2644.7377 - reconstruction_loss: 2638.7581 - kl_loss: 3.7529\n",
      "Epoch 74/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2644.8041 - reconstruction_loss: 2637.8369 - kl_loss: 3.7359\n",
      "Epoch 75/300\n",
      "69/69 [==============================] - 12s 169ms/step - total_loss: 2644.0677 - reconstruction_loss: 2637.5056 - kl_loss: 3.6530\n",
      "Epoch 76/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2645.5675 - reconstruction_loss: 2639.2297 - kl_loss: 3.8207\n",
      "Epoch 77/300\n",
      "69/69 [==============================] - 12s 169ms/step - total_loss: 2641.4986 - reconstruction_loss: 2635.9104 - kl_loss: 3.7741\n",
      "Epoch 78/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2649.3666 - reconstruction_loss: 2640.0676 - kl_loss: 3.8493\n",
      "Epoch 79/300\n",
      "69/69 [==============================] - 12s 169ms/step - total_loss: 2641.7845 - reconstruction_loss: 2636.0593 - kl_loss: 3.7656\n",
      "Epoch 80/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2642.2811 - reconstruction_loss: 2639.8679 - kl_loss: 3.7845\n",
      "Epoch 81/300\n",
      "69/69 [==============================] - 12s 169ms/step - total_loss: 2642.9036 - reconstruction_loss: 2635.9688 - kl_loss: 3.8023\n",
      "Epoch 82/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2643.2438 - reconstruction_loss: 2635.9324 - kl_loss: 3.7009\n",
      "Epoch 83/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2641.5776 - reconstruction_loss: 2636.0698 - kl_loss: 3.8603\n",
      "Epoch 84/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2639.7092 - reconstruction_loss: 2635.7639 - kl_loss: 3.6729\n",
      "Epoch 85/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2642.2431 - reconstruction_loss: 2636.4382 - kl_loss: 3.6956\n",
      "Epoch 86/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2651.9973 - reconstruction_loss: 2644.9792 - kl_loss: 3.9293\n",
      "Epoch 87/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2642.1921 - reconstruction_loss: 2637.6790 - kl_loss: 3.6946\n",
      "Epoch 88/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2644.6807 - reconstruction_loss: 2639.8755 - kl_loss: 3.7573\n",
      "Epoch 89/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2640.1502 - reconstruction_loss: 2634.4807 - kl_loss: 3.7874\n",
      "Epoch 90/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2650.4257 - reconstruction_loss: 2641.4968 - kl_loss: 3.7522\n",
      "Epoch 91/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2641.3321 - reconstruction_loss: 2636.0417 - kl_loss: 3.6894\n",
      "Epoch 92/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2647.8042 - reconstruction_loss: 2640.7747 - kl_loss: 3.8822\n",
      "Epoch 93/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2639.6113 - reconstruction_loss: 2633.7437 - kl_loss: 3.7139\n",
      "Epoch 94/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2638.1348 - reconstruction_loss: 2635.4026 - kl_loss: 3.7074\n",
      "Epoch 95/300\n",
      "69/69 [==============================] - 12s 171ms/step - total_loss: 2645.7184 - reconstruction_loss: 2640.3518 - kl_loss: 3.7771\n",
      "Epoch 96/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2643.0583 - reconstruction_loss: 2635.6008 - kl_loss: 3.8819\n",
      "Epoch 97/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2640.5974 - reconstruction_loss: 2636.9070 - kl_loss: 3.8902\n",
      "Epoch 98/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2641.5685 - reconstruction_loss: 2633.2668 - kl_loss: 3.7512\n",
      "Epoch 99/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2636.1203 - reconstruction_loss: 2632.0195 - kl_loss: 3.7985\n",
      "Epoch 100/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2639.0735 - reconstruction_loss: 2633.2908 - kl_loss: 3.7734\n",
      "Epoch 101/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2638.5859 - reconstruction_loss: 2632.7686 - kl_loss: 3.7929\n",
      "Epoch 102/300\n",
      "69/69 [==============================] - 12s 171ms/step - total_loss: 2636.8916 - reconstruction_loss: 2632.2886 - kl_loss: 3.7812\n",
      "Epoch 103/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2635.8032 - reconstruction_loss: 2632.0125 - kl_loss: 3.7353\n",
      "Epoch 104/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2648.8907 - reconstruction_loss: 2648.6943 - kl_loss: 4.1690\n",
      "Epoch 105/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2648.3389 - reconstruction_loss: 2643.3228 - kl_loss: 3.8504\n",
      "Epoch 106/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2648.4357 - reconstruction_loss: 2642.6477 - kl_loss: 3.8044\n",
      "Epoch 107/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2640.7875 - reconstruction_loss: 2634.9165 - kl_loss: 3.8453\n",
      "Epoch 108/300\n",
      "69/69 [==============================] - 12s 169ms/step - total_loss: 2639.1850 - reconstruction_loss: 2632.0254 - kl_loss: 3.7620\n",
      "Epoch 109/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2640.3264 - reconstruction_loss: 2635.1296 - kl_loss: 3.8657\n",
      "Epoch 110/300\n",
      "69/69 [==============================] - 12s 169ms/step - total_loss: 2636.2413 - reconstruction_loss: 2630.8479 - kl_loss: 3.7707\n",
      "Epoch 111/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2637.9662 - reconstruction_loss: 2632.2268 - kl_loss: 3.8439\n",
      "Epoch 112/300\n",
      "69/69 [==============================] - 12s 169ms/step - total_loss: 2639.9980 - reconstruction_loss: 2632.9172 - kl_loss: 3.8934\n",
      "Epoch 113/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2638.3117 - reconstruction_loss: 2631.9453 - kl_loss: 3.8096\n",
      "Epoch 114/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2635.2586 - reconstruction_loss: 2629.9795 - kl_loss: 3.8178\n",
      "Epoch 115/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2637.3382 - reconstruction_loss: 2631.7317 - kl_loss: 3.8139\n",
      "Epoch 116/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2637.1145 - reconstruction_loss: 2631.7097 - kl_loss: 3.8128\n",
      "Epoch 117/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2635.6579 - reconstruction_loss: 2630.5767 - kl_loss: 3.8598\n",
      "Epoch 118/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2634.7462 - reconstruction_loss: 2630.4539 - kl_loss: 3.7953\n",
      "Epoch 119/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2635.1071 - reconstruction_loss: 2629.1289 - kl_loss: 3.8694\n",
      "Epoch 120/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2633.7703 - reconstruction_loss: 2630.0447 - kl_loss: 3.8748\n",
      "Epoch 121/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2638.2992 - reconstruction_loss: 2631.2253 - kl_loss: 3.8968\n",
      "Epoch 122/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2634.3511 - reconstruction_loss: 2630.3687 - kl_loss: 3.8928\n",
      "Epoch 123/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2635.3572 - reconstruction_loss: 2628.8623 - kl_loss: 3.9067\n",
      "Epoch 124/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2635.2073 - reconstruction_loss: 2629.9019 - kl_loss: 3.8841\n",
      "Epoch 125/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2637.7996 - reconstruction_loss: 2632.3118 - kl_loss: 3.8803\n",
      "Epoch 126/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2636.1027 - reconstruction_loss: 2629.8086 - kl_loss: 3.8892\n",
      "Epoch 127/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2638.4644 - reconstruction_loss: 2633.5391 - kl_loss: 3.9021\n",
      "Epoch 128/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2635.7215 - reconstruction_loss: 2630.3979 - kl_loss: 3.8216\n",
      "Epoch 129/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2635.6891 - reconstruction_loss: 2630.5613 - kl_loss: 3.8461\n",
      "Epoch 130/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2634.9934 - reconstruction_loss: 2629.9790 - kl_loss: 3.8234\n",
      "Epoch 131/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2639.8522 - reconstruction_loss: 2631.0671 - kl_loss: 3.8344\n",
      "Epoch 132/300\n",
      "69/69 [==============================] - 12s 173ms/step - total_loss: 2632.9248 - reconstruction_loss: 2628.2725 - kl_loss: 3.8771\n",
      "Epoch 133/300\n",
      "69/69 [==============================] - 12s 171ms/step - total_loss: 2633.2177 - reconstruction_loss: 2629.2722 - kl_loss: 3.8278\n",
      "Epoch 134/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2635.8930 - reconstruction_loss: 2629.8516 - kl_loss: 3.9028\n",
      "Epoch 135/300\n",
      "69/69 [==============================] - 12s 171ms/step - total_loss: 2646.6094 - reconstruction_loss: 2643.2283 - kl_loss: 4.0940\n",
      "Epoch 136/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2650.0081 - reconstruction_loss: 2644.5168 - kl_loss: 3.9649\n",
      "Epoch 137/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2644.6517 - reconstruction_loss: 2638.3494 - kl_loss: 3.8271\n",
      "Epoch 138/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2647.1265 - reconstruction_loss: 2641.7925 - kl_loss: 3.8332\n",
      "Epoch 139/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2643.2677 - reconstruction_loss: 2635.7554 - kl_loss: 3.7721\n",
      "Epoch 140/300\n",
      "69/69 [==============================] - 12s 170ms/step - total_loss: 2640.0658 - reconstruction_loss: 2632.4082 - kl_loss: 3.8565\n",
      "Epoch 141/300\n",
      "69/69 [==============================] - 12s 171ms/step - total_loss: 2640.8091 - reconstruction_loss: 2633.9565 - kl_loss: 3.8705\n",
      "Epoch 142/300\n",
      "69/69 [==============================] - 12s 172ms/step - total_loss: 2636.3828 - reconstruction_loss: 2630.4131 - kl_loss: 3.8806\n",
      "Epoch 143/300\n",
      "69/69 [==============================] - 12s 173ms/step - total_loss: 2640.9740 - reconstruction_loss: 2634.2642 - kl_loss: 3.9393\n",
      "Epoch 144/300\n",
      "69/69 [==============================] - 12s 171ms/step - total_loss: 2639.1528 - reconstruction_loss: 2633.3062 - kl_loss: 3.9151\n",
      "Epoch 145/300\n",
      "69/69 [==============================] - 12s 173ms/step - total_loss: 2638.6439 - reconstruction_loss: 2633.5647 - kl_loss: 3.8052\n",
      "Epoch 146/300\n",
      "69/69 [==============================] - 12s 174ms/step - total_loss: 2638.2677 - reconstruction_loss: 2633.7566 - kl_loss: 3.8912\n",
      "Epoch 147/300\n",
      "69/69 [==============================] - 12s 172ms/step - total_loss: 2638.1538 - reconstruction_loss: 2635.5413 - kl_loss: 3.8104\n",
      "Epoch 148/300\n",
      "69/69 [==============================] - 12s 171ms/step - total_loss: 2638.1967 - reconstruction_loss: 2630.7336 - kl_loss: 3.9190\n",
      "Epoch 149/300\n",
      "69/69 [==============================] - 12s 171ms/step - total_loss: 2637.5226 - reconstruction_loss: 2631.3618 - kl_loss: 3.8787\n",
      "Epoch 150/300\n",
      "69/69 [==============================] - 12s 173ms/step - total_loss: 2635.7071 - reconstruction_loss: 2629.7061 - kl_loss: 3.8272\n",
      "Epoch 151/300\n",
      "69/69 [==============================] - 12s 173ms/step - total_loss: 2638.3645 - reconstruction_loss: 2634.9302 - kl_loss: 3.7578\n",
      "Epoch 152/300\n",
      "69/69 [==============================] - 12s 173ms/step - total_loss: 2641.2272 - reconstruction_loss: 2634.7925 - kl_loss: 3.7156\n",
      "Epoch 153/300\n",
      "69/69 [==============================] - 12s 172ms/step - total_loss: 2635.8617 - reconstruction_loss: 2630.3389 - kl_loss: 3.9071\n",
      "Epoch 154/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2633.3938 - reconstruction_loss: 2629.2007 - kl_loss: 3.9807\n",
      "Epoch 155/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2634.4927 - reconstruction_loss: 2629.3315 - kl_loss: 3.8262\n",
      "Epoch 156/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2644.0065 - reconstruction_loss: 2644.4106 - kl_loss: 4.0288\n",
      "Epoch 157/300\n",
      "69/69 [==============================] - 13s 187ms/step - total_loss: 2649.5267 - reconstruction_loss: 2635.6992 - kl_loss: 3.8395\n",
      "Epoch 158/300\n",
      "69/69 [==============================] - 14s 193ms/step - total_loss: 2638.6082 - reconstruction_loss: 2631.4265 - kl_loss: 3.9825\n",
      "Epoch 159/300\n",
      "69/69 [==============================] - 14s 191ms/step - total_loss: 2633.7402 - reconstruction_loss: 2629.7769 - kl_loss: 3.8328\n",
      "Epoch 160/300\n",
      "69/69 [==============================] - 13s 187ms/step - total_loss: 2647.1113 - reconstruction_loss: 2645.8159 - kl_loss: 4.0904\n",
      "Epoch 161/300\n",
      "69/69 [==============================] - 13s 184ms/step - total_loss: 2649.6642 - reconstruction_loss: 2645.1619 - kl_loss: 4.0275\n",
      "Epoch 162/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2645.0759 - reconstruction_loss: 2636.6326 - kl_loss: 3.8652\n",
      "Epoch 163/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2637.8825 - reconstruction_loss: 2631.1272 - kl_loss: 3.8764\n",
      "Epoch 164/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2634.2274 - reconstruction_loss: 2628.4797 - kl_loss: 3.8503\n",
      "Epoch 165/300\n",
      "69/69 [==============================] - 13s 179ms/step - total_loss: 2635.2479 - reconstruction_loss: 2630.0610 - kl_loss: 3.8221\n",
      "Epoch 166/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2633.0190 - reconstruction_loss: 2627.8694 - kl_loss: 3.7798\n",
      "Epoch 167/300\n",
      "69/69 [==============================] - 13s 179ms/step - total_loss: 2636.7430 - reconstruction_loss: 2629.3105 - kl_loss: 3.8428\n",
      "Epoch 168/300\n",
      "69/69 [==============================] - 13s 179ms/step - total_loss: 2634.7661 - reconstruction_loss: 2629.7632 - kl_loss: 3.9246\n",
      "Epoch 169/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2644.2824 - reconstruction_loss: 2635.3503 - kl_loss: 3.8424\n",
      "Epoch 170/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2639.8681 - reconstruction_loss: 2634.3154 - kl_loss: 3.8465\n",
      "Epoch 171/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2639.2631 - reconstruction_loss: 2636.0054 - kl_loss: 3.8334\n",
      "Epoch 172/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2649.3976 - reconstruction_loss: 2640.8396 - kl_loss: 3.9050\n",
      "Epoch 173/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2637.9359 - reconstruction_loss: 2631.4668 - kl_loss: 3.8554\n",
      "Epoch 174/300\n",
      "69/69 [==============================] - 12s 176ms/step - total_loss: 2638.8370 - reconstruction_loss: 2630.6880 - kl_loss: 3.8091\n",
      "Epoch 175/300\n",
      "69/69 [==============================] - 13s 179ms/step - total_loss: 2635.9603 - reconstruction_loss: 2629.5198 - kl_loss: 3.8711\n",
      "Epoch 176/300\n",
      "69/69 [==============================] - 12s 175ms/step - total_loss: 2633.8508 - reconstruction_loss: 2628.8860 - kl_loss: 3.8658\n",
      "Epoch 177/300\n",
      "69/69 [==============================] - 13s 177ms/step - total_loss: 2635.7831 - reconstruction_loss: 2631.1604 - kl_loss: 3.8853\n",
      "Epoch 178/300\n",
      "69/69 [==============================] - 12s 176ms/step - total_loss: 2639.1079 - reconstruction_loss: 2632.9092 - kl_loss: 3.8977\n",
      "Epoch 179/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2634.5431 - reconstruction_loss: 2629.8179 - kl_loss: 3.8690\n",
      "Epoch 180/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2635.0299 - reconstruction_loss: 2630.0569 - kl_loss: 3.7527\n",
      "Epoch 181/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2634.4896 - reconstruction_loss: 2628.2766 - kl_loss: 3.7728\n",
      "Epoch 182/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2634.2453 - reconstruction_loss: 2629.5161 - kl_loss: 3.8901\n",
      "Epoch 183/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2634.5104 - reconstruction_loss: 2631.1868 - kl_loss: 3.8103\n",
      "Epoch 184/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2639.1532 - reconstruction_loss: 2637.2639 - kl_loss: 4.0153\n",
      "Epoch 185/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2665.9479 - reconstruction_loss: 2669.8308 - kl_loss: 4.6256\n",
      "Epoch 186/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2656.8937 - reconstruction_loss: 2645.1238 - kl_loss: 4.1934\n",
      "Epoch 187/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2639.2803 - reconstruction_loss: 2634.7395 - kl_loss: 3.9317\n",
      "Epoch 188/300\n",
      "69/69 [==============================] - 13s 184ms/step - total_loss: 2642.4124 - reconstruction_loss: 2636.0383 - kl_loss: 3.9174\n",
      "Epoch 189/300\n",
      "69/69 [==============================] - 13s 184ms/step - total_loss: 2644.2636 - reconstruction_loss: 2635.9680 - kl_loss: 3.8709\n",
      "Epoch 190/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2635.6388 - reconstruction_loss: 2631.9031 - kl_loss: 3.9937\n",
      "Epoch 191/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2645.2230 - reconstruction_loss: 2639.3479 - kl_loss: 4.1054\n",
      "Epoch 192/300\n",
      "69/69 [==============================] - 13s 184ms/step - total_loss: 2641.4703 - reconstruction_loss: 2635.6174 - kl_loss: 3.8920\n",
      "Epoch 193/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2639.3678 - reconstruction_loss: 2633.0544 - kl_loss: 3.7952\n",
      "Epoch 194/300\n",
      "69/69 [==============================] - 13s 184ms/step - total_loss: 2636.4708 - reconstruction_loss: 2630.6082 - kl_loss: 3.8054\n",
      "Epoch 195/300\n",
      "69/69 [==============================] - 13s 191ms/step - total_loss: 2642.5819 - reconstruction_loss: 2638.8044 - kl_loss: 4.0927\n",
      "Epoch 196/300\n",
      "69/69 [==============================] - 13s 188ms/step - total_loss: 2652.4591 - reconstruction_loss: 2648.9138 - kl_loss: 4.3640\n",
      "Epoch 197/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2663.7708 - reconstruction_loss: 2656.0110 - kl_loss: 4.4344\n",
      "Epoch 198/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2659.1380 - reconstruction_loss: 2655.4148 - kl_loss: 4.4754\n",
      "Epoch 199/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2667.4591 - reconstruction_loss: 2655.3452 - kl_loss: 4.6482\n",
      "Epoch 200/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2651.1722 - reconstruction_loss: 2646.0952 - kl_loss: 4.2535\n",
      "Epoch 201/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2649.5381 - reconstruction_loss: 2643.4121 - kl_loss: 4.2452\n",
      "Epoch 202/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2645.6197 - reconstruction_loss: 2639.9866 - kl_loss: 4.2448\n",
      "Epoch 203/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2644.4326 - reconstruction_loss: 2638.1672 - kl_loss: 4.0682\n",
      "Epoch 204/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2640.2034 - reconstruction_loss: 2637.3127 - kl_loss: 3.8066\n",
      "Epoch 205/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2638.9480 - reconstruction_loss: 2631.4277 - kl_loss: 3.6897\n",
      "Epoch 206/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2634.9968 - reconstruction_loss: 2628.5388 - kl_loss: 3.7855\n",
      "Epoch 207/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2635.2920 - reconstruction_loss: 2629.6326 - kl_loss: 3.8254\n",
      "Epoch 208/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2634.2034 - reconstruction_loss: 2628.4683 - kl_loss: 3.8332\n",
      "Epoch 209/300\n",
      "69/69 [==============================] - 13s 179ms/step - total_loss: 2635.5509 - reconstruction_loss: 2628.4412 - kl_loss: 3.8910\n",
      "Epoch 210/300\n",
      "69/69 [==============================] - 13s 179ms/step - total_loss: 2633.0997 - reconstruction_loss: 2628.4329 - kl_loss: 3.9064\n",
      "Epoch 211/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2633.5066 - reconstruction_loss: 2627.6628 - kl_loss: 3.8708\n",
      "Epoch 212/300\n",
      "69/69 [==============================] - 13s 184ms/step - total_loss: 2634.2986 - reconstruction_loss: 2628.6619 - kl_loss: 3.8933\n",
      "Epoch 213/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2638.0948 - reconstruction_loss: 2631.2551 - kl_loss: 4.0211\n",
      "Epoch 214/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2637.0973 - reconstruction_loss: 2631.3940 - kl_loss: 3.9851\n",
      "Epoch 215/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2637.6371 - reconstruction_loss: 2632.7144 - kl_loss: 3.9385\n",
      "Epoch 216/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2634.4300 - reconstruction_loss: 2630.6243 - kl_loss: 4.0928\n",
      "Epoch 217/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2635.7529 - reconstruction_loss: 2629.2134 - kl_loss: 4.0506\n",
      "Epoch 218/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2635.3554 - reconstruction_loss: 2631.8215 - kl_loss: 4.2175\n",
      "Epoch 219/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2640.9541 - reconstruction_loss: 2635.0544 - kl_loss: 4.1640\n",
      "Epoch 220/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2645.7560 - reconstruction_loss: 2641.2454 - kl_loss: 3.9678\n",
      "Epoch 221/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2638.6460 - reconstruction_loss: 2634.4766 - kl_loss: 4.0334\n",
      "Epoch 222/300\n",
      "69/69 [==============================] - 13s 189ms/step - total_loss: 2640.9126 - reconstruction_loss: 2635.4856 - kl_loss: 4.1626\n",
      "Epoch 223/300\n",
      "69/69 [==============================] - 13s 184ms/step - total_loss: 2647.0082 - reconstruction_loss: 2640.3743 - kl_loss: 4.4587\n",
      "Epoch 224/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2649.8914 - reconstruction_loss: 2646.5823 - kl_loss: 4.2952\n",
      "Epoch 225/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2650.3173 - reconstruction_loss: 2644.0393 - kl_loss: 4.1114\n",
      "Epoch 226/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2646.3154 - reconstruction_loss: 2641.3765 - kl_loss: 3.9985\n",
      "Epoch 227/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2642.8106 - reconstruction_loss: 2637.6667 - kl_loss: 4.0726\n",
      "Epoch 228/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2643.8603 - reconstruction_loss: 2641.1772 - kl_loss: 4.8933\n",
      "Epoch 229/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2647.4514 - reconstruction_loss: 2639.6641 - kl_loss: 4.6223\n",
      "Epoch 230/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2643.4656 - reconstruction_loss: 2636.3650 - kl_loss: 4.1176\n",
      "Epoch 231/300\n",
      "69/69 [==============================] - 12s 176ms/step - total_loss: 2641.3326 - reconstruction_loss: 2635.9817 - kl_loss: 3.9944\n",
      "Epoch 232/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2642.5617 - reconstruction_loss: 2635.9021 - kl_loss: 3.9801\n",
      "Epoch 233/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2640.6683 - reconstruction_loss: 2635.6526 - kl_loss: 4.0763\n",
      "Epoch 234/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2643.0682 - reconstruction_loss: 2638.3894 - kl_loss: 4.1371\n",
      "Epoch 235/300\n",
      "69/69 [==============================] - 13s 179ms/step - total_loss: 2646.4423 - reconstruction_loss: 2640.9097 - kl_loss: 4.2908\n",
      "Epoch 236/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2644.2794 - reconstruction_loss: 2638.8484 - kl_loss: 4.1179\n",
      "Epoch 237/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2644.7255 - reconstruction_loss: 2639.2437 - kl_loss: 4.1185\n",
      "Epoch 238/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2640.8379 - reconstruction_loss: 2636.1377 - kl_loss: 4.1520\n",
      "Epoch 239/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2643.7982 - reconstruction_loss: 2637.7710 - kl_loss: 4.3423\n",
      "Epoch 240/300\n",
      "69/69 [==============================] - 13s 179ms/step - total_loss: 2644.3155 - reconstruction_loss: 2639.3430 - kl_loss: 4.1951\n",
      "Epoch 241/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2646.6993 - reconstruction_loss: 2639.5735 - kl_loss: 4.0282\n",
      "Epoch 242/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2642.6013 - reconstruction_loss: 2637.5322 - kl_loss: 3.9411\n",
      "Epoch 243/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2642.2284 - reconstruction_loss: 2636.3789 - kl_loss: 3.8334\n",
      "Epoch 244/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2665.6710 - reconstruction_loss: 2677.3872 - kl_loss: 3.6503\n",
      "Epoch 245/300\n",
      "69/69 [==============================] - 13s 179ms/step - total_loss: 2672.2074 - reconstruction_loss: 2651.3325 - kl_loss: 4.3463\n",
      "Epoch 246/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2643.7530 - reconstruction_loss: 2638.7903 - kl_loss: 4.0551\n",
      "Epoch 247/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2644.7313 - reconstruction_loss: 2637.7798 - kl_loss: 4.0956\n",
      "Epoch 248/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2643.8873 - reconstruction_loss: 2636.9216 - kl_loss: 4.2099\n",
      "Epoch 249/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2644.5033 - reconstruction_loss: 2638.8699 - kl_loss: 4.1132\n",
      "Epoch 250/300\n",
      "69/69 [==============================] - 13s 187ms/step - total_loss: 2645.6751 - reconstruction_loss: 2638.0791 - kl_loss: 4.0926\n",
      "Epoch 251/300\n",
      "69/69 [==============================] - 12s 175ms/step - total_loss: 2642.5082 - reconstruction_loss: 2637.4326 - kl_loss: 3.9729\n",
      "Epoch 252/300\n",
      "69/69 [==============================] - 13s 184ms/step - total_loss: 2645.5203 - reconstruction_loss: 2641.8584 - kl_loss: 3.8909\n",
      "Epoch 253/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2650.0874 - reconstruction_loss: 2644.1006 - kl_loss: 3.9088\n",
      "Epoch 254/300\n",
      "69/69 [==============================] - 13s 187ms/step - total_loss: 2648.3209 - reconstruction_loss: 2642.5813 - kl_loss: 3.9439\n",
      "Epoch 255/300\n",
      "69/69 [==============================] - 13s 179ms/step - total_loss: 2646.6846 - reconstruction_loss: 2640.6077 - kl_loss: 3.8931\n",
      "Epoch 256/300\n",
      "69/69 [==============================] - 12s 176ms/step - total_loss: 2646.5306 - reconstruction_loss: 2639.9412 - kl_loss: 3.8224\n",
      "Epoch 257/300\n",
      "69/69 [==============================] - 13s 179ms/step - total_loss: 2642.7319 - reconstruction_loss: 2637.5090 - kl_loss: 3.8163\n",
      "Epoch 258/300\n",
      "69/69 [==============================] - 12s 177ms/step - total_loss: 2639.2242 - reconstruction_loss: 2634.7534 - kl_loss: 3.8349\n",
      "Epoch 259/300\n",
      "69/69 [==============================] - 13s 179ms/step - total_loss: 2640.5212 - reconstruction_loss: 2634.5166 - kl_loss: 3.7685\n",
      "Epoch 260/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2650.9831 - reconstruction_loss: 2654.2859 - kl_loss: 3.5939\n",
      "Epoch 261/300\n",
      "69/69 [==============================] - 13s 188ms/step - total_loss: 2646.7602 - reconstruction_loss: 2640.8171 - kl_loss: 3.6522\n",
      "Epoch 262/300\n",
      "69/69 [==============================] - 13s 188ms/step - total_loss: 2658.1726 - reconstruction_loss: 2662.9319 - kl_loss: 5.5643\n",
      "Epoch 263/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2660.9372 - reconstruction_loss: 2648.0059 - kl_loss: 4.0963\n",
      "Epoch 264/300\n",
      "69/69 [==============================] - 13s 187ms/step - total_loss: 2647.8997 - reconstruction_loss: 2643.5642 - kl_loss: 3.9538\n",
      "Epoch 265/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2643.0020 - reconstruction_loss: 2636.5723 - kl_loss: 3.7876\n",
      "Epoch 266/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2640.4623 - reconstruction_loss: 2636.3950 - kl_loss: 3.7938\n",
      "Epoch 267/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2641.6654 - reconstruction_loss: 2635.4312 - kl_loss: 3.7733\n",
      "Epoch 268/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2640.4306 - reconstruction_loss: 2634.5793 - kl_loss: 3.7760\n",
      "Epoch 269/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2641.8439 - reconstruction_loss: 2634.7510 - kl_loss: 3.9507\n",
      "Epoch 270/300\n",
      "69/69 [==============================] - 12s 176ms/step - total_loss: 2639.1365 - reconstruction_loss: 2634.3218 - kl_loss: 3.9165\n",
      "Epoch 271/300\n",
      "69/69 [==============================] - 13s 178ms/step - total_loss: 2639.6510 - reconstruction_loss: 2634.0007 - kl_loss: 3.8016\n",
      "Epoch 272/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2641.6787 - reconstruction_loss: 2636.4563 - kl_loss: 3.9844\n",
      "Epoch 273/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2642.3923 - reconstruction_loss: 2634.9150 - kl_loss: 4.1154\n",
      "Epoch 274/300\n",
      "69/69 [==============================] - 13s 184ms/step - total_loss: 2639.1665 - reconstruction_loss: 2635.0547 - kl_loss: 4.0572\n",
      "Epoch 275/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2645.4524 - reconstruction_loss: 2639.3130 - kl_loss: 4.0048\n",
      "Epoch 276/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2643.0231 - reconstruction_loss: 2639.6555 - kl_loss: 3.9664\n",
      "Epoch 277/300\n",
      "69/69 [==============================] - 13s 184ms/step - total_loss: 2644.2941 - reconstruction_loss: 2638.5205 - kl_loss: 3.9273\n",
      "Epoch 278/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2642.8411 - reconstruction_loss: 2636.7695 - kl_loss: 3.8405\n",
      "Epoch 279/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2645.4539 - reconstruction_loss: 2636.8311 - kl_loss: 3.9387\n",
      "Epoch 280/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2638.4923 - reconstruction_loss: 2633.0669 - kl_loss: 3.8516\n",
      "Epoch 281/300\n",
      "69/69 [==============================] - 13s 187ms/step - total_loss: 2640.5122 - reconstruction_loss: 2636.6577 - kl_loss: 3.7258\n",
      "Epoch 282/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2639.0980 - reconstruction_loss: 2632.5000 - kl_loss: 3.9241\n",
      "Epoch 283/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2637.6962 - reconstruction_loss: 2630.5618 - kl_loss: 3.8845\n",
      "Epoch 284/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2634.1906 - reconstruction_loss: 2629.9402 - kl_loss: 3.7746\n",
      "Epoch 285/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2642.9851 - reconstruction_loss: 2639.6082 - kl_loss: 3.7748\n",
      "Epoch 286/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2640.0310 - reconstruction_loss: 2640.1206 - kl_loss: 4.0492\n",
      "Epoch 287/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2647.6111 - reconstruction_loss: 2640.8672 - kl_loss: 3.8071\n",
      "Epoch 288/300\n",
      "69/69 [==============================] - 13s 182ms/step - total_loss: 2654.8707 - reconstruction_loss: 2644.2705 - kl_loss: 3.9654\n",
      "Epoch 289/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2639.2627 - reconstruction_loss: 2631.4458 - kl_loss: 3.7795\n",
      "Epoch 290/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2638.1817 - reconstruction_loss: 2633.9373 - kl_loss: 3.7405\n",
      "Epoch 291/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2639.5609 - reconstruction_loss: 2637.0935 - kl_loss: 3.8089\n",
      "Epoch 292/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2648.1995 - reconstruction_loss: 2642.0159 - kl_loss: 3.8841\n",
      "Epoch 293/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2646.5031 - reconstruction_loss: 2639.0278 - kl_loss: 3.8129\n",
      "Epoch 294/300\n",
      "69/69 [==============================] - 13s 181ms/step - total_loss: 2645.3800 - reconstruction_loss: 2641.6841 - kl_loss: 3.8526\n",
      "Epoch 295/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2645.8934 - reconstruction_loss: 2636.6953 - kl_loss: 3.8420\n",
      "Epoch 296/300\n",
      "69/69 [==============================] - 13s 186ms/step - total_loss: 2639.1774 - reconstruction_loss: 2632.8552 - kl_loss: 3.8351\n",
      "Epoch 297/300\n",
      "69/69 [==============================] - 13s 185ms/step - total_loss: 2637.6619 - reconstruction_loss: 2631.5300 - kl_loss: 3.9430\n",
      "Epoch 298/300\n",
      "69/69 [==============================] - 13s 183ms/step - total_loss: 2638.0240 - reconstruction_loss: 2632.4666 - kl_loss: 4.0202\n",
      "Epoch 299/300\n",
      "69/69 [==============================] - 13s 177ms/step - total_loss: 2636.5257 - reconstruction_loss: 2631.1931 - kl_loss: 3.9261\n",
      "Epoch 300/300\n",
      "69/69 [==============================] - 13s 180ms/step - total_loss: 2642.7759 - reconstruction_loss: 2636.6384 - kl_loss: 3.8934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c3b1e6b0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(whole_dataset, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(whole_dataset))[0]\n",
    "sample = np.expand_dims(sample, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 296ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed = vae.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed[0].shape\n",
    "reconstructed = reconstructed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed *= 128\n",
    "reconstructed += 64\n",
    "reconstructed = np.clip(0, 255, reconstructed)\n",
    "reconstructed = reconstructed.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x32a72b130>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x328bc86d0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, s = encoder(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
